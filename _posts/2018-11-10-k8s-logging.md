---
layout:     post
title:      k8s集群日志、监控、调用链的实践
subtitle:   猪齿鱼架构所感
date:       2018-11-10
author:     Hxd
header-img: img/city.jpg
catalog: true
tags: 
  - 实习
  - k8s
  - 日志链路
---
# 开门见山
上一周所干的事其实也不是很多，主要了解了集群日志的收集。日志主要有两种打法，一是直接输出到控制台，二是输出到日志文件中。在Docker或者k8s中最常见就是这两种。其中直接打印日志的方法就是stdout日志，这种方式可以用`docker logs` 或者`kubectl logs` 命令查看。这种输出标准在linux上面其实是往一个ID为零的文件表述符里面去写`（0为stdin，1为stdout，2为stderr）`。文件日志就是写在磁盘上的日志，比如生成`test.log`文件等，这个是存在于容器内部的。在Docker或K8s里，目前比较推崇标准输出的日志。标准输出日志的原理在于，当在启动进程的时候，进程之间有一个父子关系，父进程可以拿到子进程的标准输出。拿到子进程标准输出的后，父进程可以对标准输出做所有希望的处理。这样一来，打印出来的日志自然不会留在容器里面，那么问题就来了，这种日志怎么收集呢？其实`docker logs`或者`kubectl logs`出来的日志是存储在容器外边的docker日志文件里，linux里是/`var/log/container` 或者 `/var/log/pods/` 里面对应的容器的日志。这时候如果想要收集这种日志就可以把的对应的文件夹挂载近容器，然后`fluent-bit`就可以收集。但是假如，要起很多的pod，每个pod都要挂载主机卷，这样似乎不太好。所以就萌生了这个想法：我可不可以让stdout分流到文件同时又打印到控制台，这样一来，`docker logs`或者`kubectl logs`能查到而且也会在容器中存在一份日志文件，这样sidecar日志收集器就可不用绑主机的卷而去共享目录文件去取这个日志文件就可以了。
查到另一种方法可以修改docker的`log driver`，让其stdout直接写到别的文件里，但是也只能是容器外边的文件[supported-logging-drivers](https://docs.docker.com/config/containers/logging/configure/#supported-logging-drivers).但是在k8s还没支持这个选项。
以sidecar容器收集日志的架构：
```
---
apiVersion: v1
metadata:
  name: config
data:
  #配置文件
  fluent-bit.conf: |+
    #;this file is generate by flb api server

    #;api:start
    #;api:service
    [SERVICE]
        Flush                       1
        Log_Level                   info
        Parsers_File                parsers.conf
    #;api:end
    #;api:start
    #;api:timing
    [INPUT]
        Name                        tail
        Path                        ${LOG_PATH}/*-log/*.log
        Mem_Buf_Limit               5MB
        Parser                      Timing
        Tag                         kube.${POD_NAME}.*
    #;api:end
    
    #;api:start
    #;api:output
    #[OUTPUT]
    #    Name                        es
    #    Match                       *
    #    Host                        10.233.19.130
    #    Port                        9200
    [OUTPUT]
        Name                        stdout
        Match                       *
    #;api:end
  parsers.conf: |
    [PARSER]
        Name   Timing
        Format regex
        Regex  (?<time>\d\d\d\d\/[^\[]*) (?<level>\[[^ ]*)(?<context>.[^"]*)
  config.yml: |
    url: https://vinkdong.com
    method: GET
    header:
      Accept: application/json, text/plain, */*
      Referer: http://vinkdong.com/
    body:
      bodyone2: |
        {
          "properties": {
            "ServerIP": {
              "type":     "text",
              "fielddata": true
            }
          }
        }
    range:
      hour:
        gte: 8
        lte: 13
      month:
        gte: 10
        lte: 12
      weekday:
        gte: 0
        lte: 5
    run_every:
      seconds: 3

    #---
    type: database
    database:
      type: mysql
      host: 192.168.99.100
      port: 3306
      database: d01
      username: root
      password: admin
    sql:
      execute:
        - INSERT INTO t01 (name, date) VALUES ("zhans",NOW());
      query:
    run_count: 100
    run_thread: 20
    #run_every:
    #  microsecond: 10
kind: ConfigMap
---
apiVersion: apps/v1beta1
kind: Deployment
metadata:
  name: timing
spec:
  replicas: 1
  template:
    metadata:
      labels:
        app: timing
    spec:
      containers:
      #收集的目标日志容器
      - name: timing
        imagePullPolicy: Always
        image: "vinkdong/timing"
        args:
        - -c
        - /timing --conf /etc/config.yml --enable_metrics 2>&1 | tee -a /var/log/stdout-log/stdout.log #这里的2>&1 | tee -a意思是既输出到终端又输出到文件，2>&1意思是包括标准输出和标准错误都要记录
        command:
        - /bin/sh
        volumeMounts:
        - mountPath: /var/log/stdout-log #stdout日志
          name: stdout-log
        - mountPath: /var/log/file-log #文件日志
          name: file-log
        - mountPath: /etc/
          name: confmap
        ports:
        - name: metrics
          containerPort: 9800
      - name: fluentbit
        imagePullPolicy: Always
        image: "fluent/fluent-bit"
        volumeMounts:
        - mountPath: /var/log/stdout-log
          name: stdout-log
        - mountPath: /var/log/file-log
          name: file-log
        - mountPath: /fluent-bit/etc/
          name: confmap
        - name: LOG_PATH
          value: "/var/log/"
      volumes:
      - name: stdout-log #共享目录
        emptyDir: {}
      - name: file-log #共享目录
        emptyDir: {}
      - name: confmap  #配置文件
        configMap:
          name: config
          items:
          - key: fluent-bit.conf
            path: fluent-bit.conf
          - key: parsers.conf
            path: parsers.conf
          - key: config.yml
            path: config.yml
```
这样，stdout日志不用挂载主机目录就可以取到，但是也增加了i/o和占用存储空间。相比每个文件收集器都要挂载主机目录要好。
## 思考：
为啥不把日志收集器单独出来呢？比如收集器专门挂载主机的日志目录并发送到集中的数据库。既然每个容器的stdout日志都会存在主机的`/var/log`里，那么就直接让日记收集器去取不就好了。但是这样的话，每部署一次新的应用都要去改动收集器的收集规则，添加相应的规则。这样就很麻烦。所以作为sidecar收集也是一个不错的选择。
参考的资料：

[Docker日志收集最佳实践](https://yq.aliyun.com/articles/72700)
[logging](https://kubernetes.io/docs/concepts/cluster-administration/logging/)
[how-do-i-save-terminal-output-to-a-file](https://askubuntu.com/questions/420981/how-do-i-save-terminal-output-to-a-file)

## 外传
如何使Prometheus数据库不用重启就能感知配置文件的改变并重新载入配置呢？这里用的是[这篇文章](https://www.weave.works/blog/prometheus-configmaps-continuous-deployment/)所描述的watch sidecar。yaml文件为：
```
---
apiVersion: v1
metadata:
  name: prometheus-config
data:
  prometheus.yml: |-
    # my global config
    global:
      scrape_interval:     15s # Set the scrape interval to every 15 seconds. Default is every 1 minute.
      evaluation_interval: 15s # Evaluate rules every 15 seconds. The default is every 1 minute.
      # scrape_timeout is set to the global default (10s).

    # Alertmanager configuration
    alerting:
      alertmanagers:
      - static_configs:
        - targets:
          # - alertmanager:9093

    # Load rules once and periodically evaluate them according to the global 'evaluation_interval'.
    rule_files:
      # - "first_rules.yml"
      # - "second_rules.yml"

    # A scrape configuration containing exactly one endpoint to scrape:
    # Here it's Prometheus itself.
    scrape_configs:
      # The job name is added as a label `job=<job_name>` to any timeseries scraped from this config.
      - job_name: 'prometheus'

        # metrics_path defaults to '/metrics'
        # scheme defaults to 'http'.

        static_configs:
          - targets: ['localhost:9090']
kind: ConfigMap
---
apiVersion: apps/v1beta1
kind: Deployment
metadata:
  name: pw
spec:
  replicas: 1
  template:
    metadata:
      labels:
        app: prometheus
    spec:
      containers:
      - name: prometheus
        imagePullPolicy: Always
        image: "registry.cn-hangzhou.aliyuncs.com/choerodon-tools/prometheus:v2.2.1"
        args: ["--web.enable-lifecycle","--config.file=/etc/prometheus/prometheus.yml"]
        ports:
        - name: metrics
          containerPort: 9090
        volumeMounts:
        - name: config-volume
          mountPath: /etc/prometheus/
      - name: watch
        image: weaveworks/watch:master-5b2a6e5
        imagePullPolicy: IfNotPresent
        args: ["-v", "-t", "-p=/etc/prometheus", "curl", "-X", "POST", "--fail", "-o", "-", "-sS", "http://localhost:9090/-/reload"] #监控该文件夹，并对Prometheus发送信息
        env:
        - name: POD_IP
          valueFrom:
            fieldRef:
              fieldPath: status.podIP
        volumeMounts:
        - name: config-volume
          mountPath: /etc/prometheus/
      volumes:
      - name: config-volume
        configMap:
          name: prometheus-config
          items: 
          - key: prometheus.yml
            path: prometheus.yml
```
watch这个应用的原理就是监视某个文件或者文件夹，若有改动则做出相应的处理，[Github地址](https://github.com/weaveworks/Watch)

# 日志链路
## 架构图
![](http://pbqgh436d.bkt.clouddn.com/18-11-8/30973004.jpg)
上一版本我们使用fluentd作为过滤和缓冲，但是现在通过修改fluent-bit输出插件，即可实现同样的效果并直接发到es数据库。
![](http://pbqgh436d.bkt.clouddn.com/18-11-8/35598222.jpg)


[fluent-bit](https://fluentbit.io/documentation/0.13/)
[es权威指南](https://www.elastic.co/guide/cn/elasticsearch/guide/current/getting-started.html)
[es数据库查询](https://n3xtchen.github.io/n3xtchen/elasticsearch/2017/07/05/elasticsearch-23-useful-query-example)

## 各个模块详解
# 监控链路
## 架构图
![](http://pbqgh436d.bkt.clouddn.com/18-11-8/48458599.jpg)

[Prometheus时序数据库](https://prometheus.io/docs/introduction/overview/)
## 各个模块详解
# 调用链路
待更新。。